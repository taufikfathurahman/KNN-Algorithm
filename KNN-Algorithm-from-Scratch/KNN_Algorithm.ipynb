{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor\n",
    "\n",
    "Berikut ini adalah langkah-langkah dalam menyelesaikan permasalahan klasifikasi menggunakan KNN :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Membaca Data Train\n",
    "\n",
    "Membaca data yang akan *ditrain* untuk mendapatkan `K` terbaik, akurasi, dan yang akan digunakan untuk memprediksi *data test* nantinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut 1</th>\n",
       "      <th>atribut 2</th>\n",
       "      <th>atribut 3</th>\n",
       "      <th>atribut 4</th>\n",
       "      <th>kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.4</td>\n",
       "      <td>61.250</td>\n",
       "      <td>10.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.2</td>\n",
       "      <td>34.375</td>\n",
       "      <td>14.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.4</td>\n",
       "      <td>46.875</td>\n",
       "      <td>10.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.6</td>\n",
       "      <td>76.250</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.2</td>\n",
       "      <td>55.000</td>\n",
       "      <td>9.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atribut 1  atribut 2  atribut 3  atribut 4  kelas\n",
       "0       17.4     61.250       10.4       21.0      1\n",
       "1       16.2     34.375       14.8       15.6      1\n",
       "2       11.4     46.875       10.8        9.9      0\n",
       "3       12.6     76.250       18.0       25.5      1\n",
       "4       16.2     55.000        9.8       15.9      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train_from_csv = pd.read_csv('dataTrain.csv')\n",
    "data_train_from_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Menghitung Euclidean Distance\n",
    "\n",
    "Dalam melakukan perhitungan jarak pada KNN dapat digunakan bebrapa teori, diantanya adalah *euclidean* dan *manhattan*. Dalam percobaan kali ini akan dilakukan dengan menggunakan teori *euclidean* dalam menghitung jaraknya.\n",
    "\n",
    "*Euclidean distance* melakukan perhitungan jarak antara dua buah titik dalam *euclidean space*. Berikut adalah formulanya :\n",
    "\n",
    "<img src=\"assets/euclidean.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclideanDistance(data_train, data_test):\n",
    "    distanceSum = 0\n",
    "    for i in range(len(data_train)-1):\n",
    "        distanceSum += (data_train[i]-data_test[i])**2\n",
    "    return np.sqrt(distanceSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. KNN Algorithm\n",
    "\n",
    "KNN merupakan algoritma yang digunakan dalam melakukan memecahkan permasalahan klasifikasi, sehingga menghasilkan output diskrit. Contoh untuk output berupa diskrit adalah output yang hasilnya pasti seperti ketika menghitung 1 + 1 = 2, jawabannya bukan mendekati 2. KNN akan melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut.\n",
    "\n",
    "KNN akan bekerja berdasarkan jarak minimum dari data baru ke data training untuk menentukan tetangga terdekat. Setelah itu akan didapatkan data mayoritas sebagai hasil prediksi dari data baru tadi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def kNearestNeighbor(data_train, data_test, k):\n",
    "    distances = {}\n",
    "    sort = {}\n",
    "    neighbors = []\n",
    "    vote_class = {}\n",
    "  \n",
    "    for i in range(len(data_train)):\n",
    "        distance = euclideanDistance(data_train.iloc[i], data_test)\n",
    "        distances[i] = distance\n",
    "  \n",
    "    sorted_distances = sorted(distances.items(), key=operator.itemgetter(1))\n",
    "  \n",
    "    for i in range(k):\n",
    "        neighbors.append(sorted_distances[i][0])\n",
    "    \n",
    "    for x in range(len(neighbors)):\n",
    "        class_in_datatrain = data_train.iloc[neighbors[x]][-1]\n",
    "    \n",
    "        if class_in_datatrain in vote_class:\n",
    "            vote_class[class_in_datatrain] += 1\n",
    "        else:\n",
    "            vote_class[class_in_datatrain] = 1\n",
    "  \n",
    "    sorted_vote_class = sorted(vote_class.items(), key=operator.itemgetter(1))\n",
    "  \n",
    "    return sorted_vote_class[-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Menghitung Akurasi\n",
    "\n",
    "Akurasi akan didapatkan dari perbandingan hasil prediksi dengan data sebenarnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionAccuracy(prediction_data, data_test):\n",
    "    accurate = 0\n",
    "  \n",
    "    for i in range(len(prediction_data)):\n",
    "        if prediction_data[i] == data_test.iloc[i][-1]:\n",
    "            accurate += 1\n",
    "      \n",
    "    return (accurate/len(prediction_data)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cross Validation & Tuning Parameter\n",
    "\n",
    "**Cross Validation**\n",
    "\n",
    "*Cross validation* merupakn metode statistik dalam melakukan evaluasi kinerja dari suatu model atau algoritma dengan melakukan pembagian data menjadi dua subset, yaitu `data pengujian` dan `data pelatihan`.\n",
    "\n",
    "> **K-Fold Cross Validation**\n",
    "K-Fold Cross Validation merupakan salah satu metode Cross validation yang bekerja dengan melipat data sebanyak K dan melakukan perulangan sebanyak `K` juga. Contohnya untuk `K` = 10:\n",
    "\n",
    "<img src=\"assets/k-fold.png\">\n",
    "\n",
    "**Tuning Parameter**\n",
    "\n",
    "Untuk mendapatkan akurasi yang terbaik saat melakukan klasifikasi di KNN, akan sangat bergantung pada nilai `K` yang kita berikan. Proses dalam mencari `K` terbaik dapat disebut sebagain *Tuning Parameter8* atau *Hyperparameter*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crossValFtTunParam(data_train_from_csv):\n",
    "    dev_by5 = int(len(data_train_from_csv)/5)\n",
    "    fold1 = data_train_from_csv.iloc[0:dev_by5]\n",
    "    fold2 = data_train_from_csv.iloc[dev_by5:dev_by5*2]\n",
    "    fold3 = data_train_from_csv.iloc[dev_by5*2:dev_by5*3]\n",
    "    fold4 = data_train_from_csv.iloc[dev_by5*3:dev_by5*4]\n",
    "    fold5 = data_train_from_csv.iloc[dev_by5*4:]\n",
    "    \n",
    "    if(len(data_train_from_csv)/5) > 100:\n",
    "        k_range = range(1, 101)\n",
    "    else:\n",
    "        k_range = range(1, dev_by5+1)\n",
    "        \n",
    "    best_k = {}\n",
    "    \n",
    "    for k in k_range:\n",
    "        accuracy_crossval = []\n",
    "        for i in range(1,6):\n",
    "            prediction_data = []\n",
    "            if i == 1:\n",
    "                data_test = fold1\n",
    "                data_train = pd.concat([fold2, fold3, fold4, fold5])\n",
    "            elif i == 2:\n",
    "                data_test = fold2\n",
    "                data_train = pd.concat([fold1, fold3, fold4, fold5])\n",
    "            elif i == 3:\n",
    "                data_test = fold3\n",
    "                data_train = pd.concat([fold1, fold2, fold4, fold5])\n",
    "            elif i == 4:\n",
    "                data_test = fold4\n",
    "                data_train = pd.concat([fold1, fold2, fold3, fold5])\n",
    "            else:\n",
    "                data_test = fold5\n",
    "                data_train = pd.concat([fold1, fold2, fold3, fold4])\n",
    "\n",
    "            for x in range(len(data_test)):\n",
    "                prediction_data.append(kNearestNeighbor(data_train, data_test.iloc[x], k))\n",
    "            \n",
    "            tmp_accuracy = predictionAccuracy(prediction_data, data_test)\n",
    "            accuracy_crossval.append(tmp_accuracy)\n",
    "        \n",
    "        best_k[k] = sum(accuracy_crossval)/len(accuracy_crossval)\n",
    "        \n",
    "    plt.scatter(k_range, best_k.values())\n",
    "    plt.title('Plot Hasil Pencarian K Terbaik')\n",
    "    plt.xlabel('Nomor K')\n",
    "    plt.ylabel('Akurasi K')\n",
    "    plt.show()\n",
    "    \n",
    "    K = max(best_k.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    print(best_k)\n",
    "        \n",
    "    return K, best_k[K]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mendapatkan K terbaik dan Akurasinya\n",
    "\n",
    "Memanggil fungsi yang telah dibuat sebelumnya untuk mendapatkan K terbaik beserta menampilakan besar akurasi yang dihasilkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 55.0, 2: 55.75, 3: 58.5, 4: 59.75, 5: 60.75, 6: 61.5, 7: 62.75, 8: 63.5, 9: 62.0, 10: 63.5, 11: 66.0, 12: 65.75, 13: 64.25, 14: 65.25, 15: 65.25, 16: 65.25, 17: 66.0, 18: 66.5, 19: 66.5, 20: 67.5, 21: 66.75, 22: 67.75, 23: 68.0, 24: 69.0, 25: 68.5, 26: 69.25, 27: 68.75, 28: 69.25, 29: 69.75, 30: 68.25, 31: 68.5, 32: 68.75, 33: 70.0, 34: 69.25, 35: 68.75, 36: 68.75, 37: 68.0, 38: 68.5, 39: 68.75, 40: 69.25, 41: 69.25, 42: 69.25, 43: 69.0, 44: 69.25, 45: 68.5, 46: 69.75, 47: 68.75, 48: 69.75, 49: 69.25, 50: 69.75, 51: 69.25, 52: 69.5, 53: 69.5, 54: 69.5, 55: 69.5, 56: 70.25, 57: 69.5, 58: 69.75, 59: 69.0, 60: 68.5, 61: 68.25, 62: 68.75, 63: 68.25, 64: 69.25, 65: 68.5, 66: 68.75, 67: 69.0, 68: 69.0, 69: 69.0, 70: 68.5, 71: 68.75, 72: 68.0, 73: 68.5, 74: 68.25, 75: 68.25, 76: 68.5, 77: 68.0, 78: 67.5, 79: 68.25, 80: 67.5}\n",
      "===============================\n",
      "|| Best k     :  56\n",
      "|| Accuracy   :  70.25 %\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "best_k, accuracy = crossValFtTunParam(data_train_from_csv)\n",
    "print('===============================')\n",
    "print('|| Best k     : ', best_k)\n",
    "print('|| Accuracy   : ', accuracy, '%')\n",
    "print('===============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Data Test CSV\n",
    "\n",
    "Setelah mengolah data train untuk mendapatkan K terbaik beserta akurasinya, sekarang adalah waktunya untuk mengolah data test untuk mendapatkan kelasnya.\n",
    "\n",
    "**1. Membaca Data Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut 1</th>\n",
       "      <th>atribut 2</th>\n",
       "      <th>atribut 3</th>\n",
       "      <th>atribut 4</th>\n",
       "      <th>kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.4</td>\n",
       "      <td>54.375</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.8</td>\n",
       "      <td>67.500</td>\n",
       "      <td>14.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.6</td>\n",
       "      <td>62.500</td>\n",
       "      <td>13.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.8</td>\n",
       "      <td>46.875</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.8</td>\n",
       "      <td>58.750</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atribut 1  atribut 2  atribut 3  atribut 4  kelas\n",
       "0        8.4     54.375       13.6       13.5    NaN\n",
       "1       10.8     67.500       14.4       22.2    NaN\n",
       "2       21.6     62.500       13.6       20.7    NaN\n",
       "3       10.8     46.875        9.0       16.8    NaN\n",
       "4       10.8     58.750       14.2       13.5    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_from_csv = pd.read_csv('dataTest.csv')\n",
    "data_test_from_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Mendapatkan Prediksi Kelas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = []\n",
    "\n",
    "for x in range(len(data_test_from_csv)):\n",
    "    prediction_data.append(int(kNearestNeighbor(data_train_from_csv, data_test_from_csv.iloc[x], best_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Menyimpan Data Hasil Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_from_csv['kelas'] = prediction_data\n",
    "data_test_from_csv.to_csv('dataHasilPrediksi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut 1</th>\n",
       "      <th>atribut 2</th>\n",
       "      <th>atribut 3</th>\n",
       "      <th>atribut 4</th>\n",
       "      <th>kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.4</td>\n",
       "      <td>54.375</td>\n",
       "      <td>13.6</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.8</td>\n",
       "      <td>67.500</td>\n",
       "      <td>14.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.6</td>\n",
       "      <td>62.500</td>\n",
       "      <td>13.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.8</td>\n",
       "      <td>46.875</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.8</td>\n",
       "      <td>58.750</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.6</td>\n",
       "      <td>61.875</td>\n",
       "      <td>11.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>54.375</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.8</td>\n",
       "      <td>45.000</td>\n",
       "      <td>10.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>42.500</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.0</td>\n",
       "      <td>58.750</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.4</td>\n",
       "      <td>73.125</td>\n",
       "      <td>10.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.6</td>\n",
       "      <td>67.500</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.8</td>\n",
       "      <td>39.375</td>\n",
       "      <td>10.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.2</td>\n",
       "      <td>53.125</td>\n",
       "      <td>12.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.2</td>\n",
       "      <td>54.375</td>\n",
       "      <td>10.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.6</td>\n",
       "      <td>73.125</td>\n",
       "      <td>14.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.6</td>\n",
       "      <td>70.625</td>\n",
       "      <td>8.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.6</td>\n",
       "      <td>45.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.8</td>\n",
       "      <td>55.625</td>\n",
       "      <td>11.6</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.2</td>\n",
       "      <td>33.750</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19.2</td>\n",
       "      <td>49.375</td>\n",
       "      <td>8.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.2</td>\n",
       "      <td>72.500</td>\n",
       "      <td>11.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.6</td>\n",
       "      <td>60.625</td>\n",
       "      <td>13.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.4</td>\n",
       "      <td>55.625</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.0</td>\n",
       "      <td>53.750</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.4</td>\n",
       "      <td>40.000</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.6</td>\n",
       "      <td>80.000</td>\n",
       "      <td>10.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.0</td>\n",
       "      <td>38.750</td>\n",
       "      <td>12.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.6</td>\n",
       "      <td>35.625</td>\n",
       "      <td>11.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.0</td>\n",
       "      <td>80.625</td>\n",
       "      <td>11.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>10.2</td>\n",
       "      <td>33.750</td>\n",
       "      <td>10.2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>22.2</td>\n",
       "      <td>64.375</td>\n",
       "      <td>15.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>10.8</td>\n",
       "      <td>38.125</td>\n",
       "      <td>13.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>10.2</td>\n",
       "      <td>60.625</td>\n",
       "      <td>10.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>6.0</td>\n",
       "      <td>55.625</td>\n",
       "      <td>11.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>7.8</td>\n",
       "      <td>66.250</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>7.2</td>\n",
       "      <td>63.750</td>\n",
       "      <td>14.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>22.8</td>\n",
       "      <td>75.000</td>\n",
       "      <td>13.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>21.6</td>\n",
       "      <td>61.250</td>\n",
       "      <td>13.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>11.4</td>\n",
       "      <td>55.000</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>8.4</td>\n",
       "      <td>69.375</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>18.0</td>\n",
       "      <td>46.875</td>\n",
       "      <td>14.4</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>19.2</td>\n",
       "      <td>42.500</td>\n",
       "      <td>13.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6.0</td>\n",
       "      <td>50.625</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>21.6</td>\n",
       "      <td>40.000</td>\n",
       "      <td>9.2</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>22.2</td>\n",
       "      <td>53.125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>11.4</td>\n",
       "      <td>45.625</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>9.6</td>\n",
       "      <td>38.125</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>7.8</td>\n",
       "      <td>41.875</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6.6</td>\n",
       "      <td>38.125</td>\n",
       "      <td>14.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>18.0</td>\n",
       "      <td>44.375</td>\n",
       "      <td>9.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>22.8</td>\n",
       "      <td>49.375</td>\n",
       "      <td>11.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>23.4</td>\n",
       "      <td>50.625</td>\n",
       "      <td>10.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>21.6</td>\n",
       "      <td>67.500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>9.6</td>\n",
       "      <td>46.250</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>19.8</td>\n",
       "      <td>59.375</td>\n",
       "      <td>13.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>20.4</td>\n",
       "      <td>62.500</td>\n",
       "      <td>11.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6.0</td>\n",
       "      <td>38.125</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>20.4</td>\n",
       "      <td>52.500</td>\n",
       "      <td>14.8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>24.0</td>\n",
       "      <td>66.250</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     atribut 1  atribut 2  atribut 3  atribut 4  kelas\n",
       "0          8.4     54.375       13.6       13.5      0\n",
       "1         10.8     67.500       14.4       22.2      1\n",
       "2         21.6     62.500       13.6       20.7      1\n",
       "3         10.8     46.875        9.0       16.8      0\n",
       "4         10.8     58.750       14.2       13.5      0\n",
       "5         21.6     61.875       11.2       18.3      1\n",
       "6          6.0     54.375       14.2       18.3      0\n",
       "7          7.8     45.000       10.2       21.6      0\n",
       "8         21.0     42.500       14.6       18.3      0\n",
       "9          6.0     58.750       12.8       21.3      0\n",
       "10        20.4     73.125       10.8       21.6      1\n",
       "11         6.6     67.500       14.8       21.0      1\n",
       "12        10.8     39.375       10.6       23.1      0\n",
       "13        10.2     53.125       12.4       19.2      0\n",
       "14         7.2     54.375       10.8       18.6      0\n",
       "15        21.6     73.125       14.8       21.9      1\n",
       "16        18.6     70.625        8.8       18.6      1\n",
       "17         6.6     45.000       15.0       21.0      0\n",
       "18        10.8     55.625       11.6       19.2      0\n",
       "19         7.2     33.750       14.0       23.7      0\n",
       "20        19.2     49.375        8.8       21.0      1\n",
       "21        19.2     72.500       11.6       21.0      1\n",
       "22         6.6     60.625       13.2       15.0      0\n",
       "23         8.4     55.625        9.8       12.6      0\n",
       "24        12.0     53.750       10.2       20.1      0\n",
       "25        14.4     40.000       13.8       16.2      0\n",
       "26        21.6     80.000       10.8       24.0      1\n",
       "27        21.0     38.750       12.4       21.6      0\n",
       "28         6.6     35.625       11.6       19.8      0\n",
       "29        18.0     80.625       11.8       24.0      1\n",
       "..         ...        ...        ...        ...    ...\n",
       "970       10.2     33.750       10.2       19.5      0\n",
       "971       22.2     64.375       15.6       19.5      1\n",
       "972       10.8     38.125       13.4       21.0      0\n",
       "973       10.2     60.625       10.4       18.0      0\n",
       "974        6.0     55.625       11.8       23.7      0\n",
       "975        7.8     66.250        9.4       13.2      0\n",
       "976        7.2     63.750       14.4       22.5      0\n",
       "977       22.8     75.000       13.2       21.0      1\n",
       "978       21.6     61.250       13.2       18.3      1\n",
       "979       11.4     55.000       14.6       14.4      0\n",
       "980        8.4     69.375       14.4       15.6      0\n",
       "981       18.0     46.875       14.4       21.9      0\n",
       "982       19.2     42.500       13.6       22.8      0\n",
       "983        6.0     50.625       13.0       19.2      0\n",
       "984       21.6     40.000        9.2       22.2      0\n",
       "985       22.2     53.125       13.0       20.1      1\n",
       "986       11.4     45.625        8.8       12.6      0\n",
       "987        9.6     38.125       15.8       16.5      0\n",
       "988        7.8     41.875       14.2       18.0      0\n",
       "989        6.6     38.125       14.8       16.8      0\n",
       "990       18.0     44.375        9.4       21.6      0\n",
       "991       22.8     49.375       11.6       21.6      1\n",
       "992       23.4     50.625       10.4       19.2      1\n",
       "993       21.6     67.500        8.0       20.4      1\n",
       "994        9.6     46.250       14.4       14.1      0\n",
       "995       19.8     59.375       13.6       21.6      1\n",
       "996       20.4     62.500       11.2       22.8      1\n",
       "997        6.0     38.125        8.0       15.6      0\n",
       "998       20.4     52.500       14.8       22.5      1\n",
       "999       24.0     66.250       16.0       23.4      1\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hasil_from_csv = pd.read_csv('dataHasilPrediksi.csv')\n",
    "data_hasil_from_csv.drop(columns=['Unnamed: 0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
